## 进程和线程的区别

**进程（Process）** 是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。

**线程（thead）** 是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。

进程：指在系统中正在运行的一个应用程序；程序一旦运行就是进程；进程——资源分配的最小单位。

线程：系统分配处理器时间资源的基本单元，或者说进程之内独立执行的一个单元执行流。线程——程序执行的最小单位。

- 切换： 线程上下文切换比进程上下文切换快得多。
- 拥有资源： 进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源。
- 系统开销： 创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O设备等，OS所付出的开销显著大于在创建或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。

## 为什么需要线程

因为进程可以使多个程序能并发进行，以提高资源的利用率和系统的吞吐量；但是还有一些缺点：

- 进程在同一时刻只能做一个任务，很多时候不能充分利用CPU资源
- 进程在执行的过程中如果发生阻塞，整个进程就会挂起，即使进程中其它任务不依赖于等待的资源，进程仍会被阻塞。

**引入线程就是为了解决以上进程的不足，线程具有以下的优点：** 

1.  从资源上来讲，开辟一个线程所需要的资源要远小于一个进程。 
2.  从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间（这种时间的差异主要由于缓存的大量未命中导致）。
3. 从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的地址空间，要进行数据的传递只能通过进程间通信的方式进行。线程则不然，属于同一个进程的不同线程之间共享同一地址空间

## 什么是协程

协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

## 协程与线程的区别

- 线程和进程都是同步机制，而协程是异步机制
- 线程是抢占式的，而协程是非抢占式的。需要用户释放使用权切换到其他协程，因为同一时间其实只有一个协程拥有运行权，相当于单线程

- 一个线程可以有多个协程，一个进程也可以有多个协程
- 协程不被操作系统内核管理，而完全是由程序控制。线程是被分割的CPU资源，协程是组织好的代码流程，线程是协程的资源。但协程不会直接使用线程，协程直接利用的是执行器关联任意线程或线程池。

## 并发和并行有什么区别

并发就是在一段时间内，多个任务都会被处理；**但在某个时刻，只有一个任务在执行**。单核处理器可以做到并发。

*比如有两个进程A和B，A运行一个时间片之后，切换到B，B运行一个时间片之后又切换到A。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序*

并行就是在同一时刻，有多个任务在执行。这个需要多核处理器才能完成。在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行，这个是物理上的多个进程同时进行。

## 进程与线程的切换流程

进程切换分两步：

1. 切换页表以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间全部作废。
2. 切换内核栈和硬件上下文。

因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。

## 为什么虚拟地址空间切换比较耗时

进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程

因此通常使用**Cache来缓存常用的地址映射，这样可以加速页表查找**，这个Cache就是TLB（translation Lookaside Buffer，TLB本质上就是一个Cache，是用来加速页表查找的）。

## 进程间通信方式有哪些

- **管道**： 管道这种通讯方式有两种限制，一是 **半双工的通信**，数据只能单向流动，二是只能在**具有亲缘关系的进程间**使用。进程的亲缘关系通常是指父子进程关系。

​	管道可以分为两类： *匿名管道* 和*命名管道*。匿名管道是单向的，只能在有亲缘关系的进程间通信；命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

- **信号**： 信号可以在任何时候发给某一进程，而无需知道该进程的状态。

> Linux系统中常用的信号：
>
> 1. SIGHUP： 用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。
> 2. SIGINT：程序终止信号。程序运行过程中，按Ctrl+C键将产生该信号。
> 3. SIGQUIT：程序退出信号。程序运行过程中，按Ctrl+\键将产生该信号。 
> 4. SIGBUS和SIGSEGV：进程访问非法地址。
> 5. SIGFPE：运算中出现致命错误，如除零操作、数据溢出等。 
> 6. SIGKILL：用户终止进程执行信号。shell下执行kill -9发送该信号。 
> 7. SIGTERM：结束进程信号。shell下执行kill 进程pid发送该信号。 
> 8. SIGALRM：定时器信号。 
> 9. SIGCLD：子进程退出信号。如果其父进程没有忽略该信号也没有处理该信号，则子进程退出后将形成僵尸进程。

- **信号量**：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

- **消息队列** ：消息队列是消息的链接表，包括Posix消息队列和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
- **共享内存**：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。 
-  **Socket**：与其他通信机制不同的是，它可用于不同机器间的进程通信。

## 进程间同步的方式有哪些

1. **临界区**：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。

优点： 保证在某一时刻只有一个线程能访问数据

缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。

2. **互斥量**： 为协调共同对一个共享资源的单独访问而设计的。比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。

优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。

缺点： 

-  互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。 
-  通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。

3. **信号量**：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。
4. **事件**：用来通知线程有一些事件已发生，从而启动后继任务的开始。

## 进程的状态与状态转换

进程在运行时有三种基本状态：就绪态、运行态和阻塞态。

1. **运行（running）态**：进程占有处理器正在运行的状态。进程已获得CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态；在多处理机系统中，则有多个进程处于执行状态。
2. **就绪（ready）态：**进程具备运行条件，等待系统分配处理器以便运行的状态。 当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。
3. **阻塞（wait）态**：又称等待态或睡眠态，指进程不具备运行条件，正在等待某个时间完成的状态。

各状态之间的转换：

1. 就绪→执行 处于就绪状态的进程，当进程调度程序为之分配了CPU后，该进程便由就绪状态转变成执行状态。
2. 执行→就绪 处于执行状态的进程在其执行过程中，因分配给它的一个时间片已用完而不得不让出处理机，于是进程从执行状态转变成就绪状态。
3. 执行→阻塞 正在执行的进程因等待某种事件发生而无法继续执行时，便从执行状态变成阻塞状态。
4. 阻塞→就绪 处于阻塞状态的进程，若其等待的事件已经发生，于是进程由阻塞状态转变为就绪状态。

## 进程调度策略有哪几种

- **先来先服务**： 非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行。另外，对I/O密集型进程也不利，因为这种进程每次进行I/O操作之后又得重新排队。
- **短作业优先**：非抢占式的调度算法，按照估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。
- **最短剩余时间优先**： 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。
- **时间片轮转**： 将所有就绪进程按照FCFS的原则排成一个队列，每次调度的适合，把CPU时间分配给队首进程，该进程可以执行一个CPU时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。
- **优先级调度**： 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

## 常见的几种内存管理机制

1. **块式管理**：将内存分为⼏个固定⼤⼩的块，每个块中只包含⼀个进程。如果程序运⾏需要内存的话，操作系统就分配给它⼀块，如果程序运⾏只需要很⼩的空间的话，分配的这块内存很⼤⼀部分⼏乎被浪费了。这些在每个块中未被利⽤的空间，我们称之为碎⽚。
2.  **页式管理**：把主存分为⼤⼩相等且固定的⼀⻚⼀⻚的形式，⻚面⼩，相对相⽐于块式管理的划分⼒度更⼤，提⾼了内存利⽤率，减少了碎⽚。⻚式管理通过⻚表对应逻辑地址和物理地址。
3. **段式管理**：⻚式管理虽然提⾼了内存利⽤率，但是⻚式管理其中的⻚实际并⽆任何实际意义。 段式管理把主存分为⼀段段的，每⼀段的空间⼜要⽐⼀⻚的空间⼩很多 。但是，最重要的是段是有实际意义的，每个段定义了⼀组逻辑信息，例如,有主程序段 MAIN、⼦程序段X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段⻚式管理机制** 。段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚，也就是说 段⻚式管理机制 中段与段之间以及段的内部的都是离散的。

## 什么是死锁？ 形成条件？ 怎么避免死锁

死锁： **在两个或多个并发进程中，如果每个进程持有某种资源而又都等待别的进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。**通俗地讲，就是两个或多个进程被**无限期地阻塞、相互等待**的一种状态。

产生死锁的必要条件：

① **互斥**（mutualexclusion），一个资源每次只能被一个进程使用；

② **不可抢占**（nopreemption），进程已获得的资源，在未使用完之前，不能强行剥夺；

③ **占有并等待（**hold andwait），一个进程因请求资源而阻塞时，对已获得的资源保持不放；

④  **环形等待**（circularwait），若干进程之间形成一种首尾相接的循环等待资源关系。

死锁的处理策略：**鸵鸟策略、预防策略、避免策略、检测与恢复策略**。

## 孤儿进程，僵尸进程，守护进程

- **孤儿进程**： 如果**父进程先退出，子进程还没退出**那么子进程将被托孤给`init进程`，这时子进程的父进程就是`init进程`

- **僵尸进程**： 进程终止后进入僵死状态(zombie),等待告知父进程自己终止,后才能完全消失.但是如果**一个进程已经终止了,但是其父进程还没有获取其状态,那么这个进程就称之为僵尸进程**

  僵尸进程还会消耗一定的系统资源,并且还保留一些概要信息供父进程查询子进程的状态可以提供父进程想要的信息.一旦父进程得到想要的信息,僵尸进程就会结束.

- **守护进程**：守护进程就是在后台运行，不与任何终端关联的进程。通常情况下守护进程在系统启动时就在运行它们以root用户或者其他特殊用户(apache和postfix)运行,并能处理一些系统级的任务.习惯上守护进程的名字通常以d结尾(sshd),但这些不是必须的.

### 如何找出孤儿进程

```
ps aux | grep Z
```



## 什么是虚拟内存

虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。

## 什么是临界区？ 如何解决冲突？

每个进程中访问临界资源的那段程序称为临界区，每次只准许一个进程进入临界区，进入后不允许其他进程进入。

1. 如果有若干进程要求进入空闲的临界区，**一次仅允许一个进程进入**；
2. 任何时候，**处于临界区内的进程不可多于一个**。如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待；
3. 进入临界区的进程要在**有限时间内退出**，以便其它进程能及时进入自己的临界区；
4. 如果进程不能进入自己的临界区，则应**让出CPU**，避免进程出现“忙等”现象。

## 局部性原理

- **时间局部性**：如果程序中的某条指令一旦执行，不久以后该指令可能再次实行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
- **空间局部性**： 一旦程序访问某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

## 什么是用户态和内核态

用户态和内核态操作系统的两种运行状态

- 内核态： 处于内核态的CPU可以访问任意的数据，包括外围设备，比如网卡、硬盘等，处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况，一般处于特权级 0 的状态我们称之为内核态。
- 用户态： 处于用户态的CPU只能受限制的访问内存，并且不允许访问外围设备，用户态下的CPU不允许独占，也就是说CPU可以被其他程序获取。

## 逻辑地址/物理地址/虚拟内存

- **逻辑地址** 是指计算机用户，看到的地址。 

  例如，当创建一个长度为100的整型数组时，操作系统返回一个逻辑上的连续空间：指针指向数组第一个元素的内存地址。由于整型元素的大小为4个字节，故第二个元素的地址时起始地址加4，以此类推。事实上，逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址(在内存条中所处的位置)，并非是连续的，只是操作系统通过地址映射，将逻辑地址映射成连续的

- **物理地址** 指的是真实物理内存的地址 更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

## Linux的4种锁机制：

- **互斥锁** matex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。
- **读写锁** rwlock， 分为读锁和写锁。处于读操作时，允许多个线程同时获得读操作。但是同一时刻只能由一个线程可以获得写锁。

- **自旋锁** spinlock， 在任何时刻同样只能有一个线程访问对象。但当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。
- **RCU**： read-copy-update， 在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。

## 内存溢出和内存泄漏

**内存溢出**

指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间。

内存溢出原因：

内存中加载的数据量过于庞大，如一次从数据库取出过多数据

集合类中有对对象的引用，使用完后未清理，使得不能回收。

代码中存在死循环或者循环产生过多重复的对象实体。

**内存泄漏**

**内存泄漏是指由于疏忽或者疏忽造成了程序未能释放掉不再使用的内存的情况**。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对这段内存的控制，因而造成了内存的浪费

内存泄漏的分类：

1. 堆内存泄漏（Heap leak）。
2. 系统资源泄漏（Resource Leak）。主要是指程序使用系统分配的资源如`Bitmap\handle\SOCKET`等没有使用对应的函数释放掉，导致系统资源的浪费。



## 页面置换算法

- **OPT（最佳页面置换算法）**：选择被淘汰的页面，将是以后永不使用的，或许是最长时间内不再被访问的页面；采用最佳置换算法可保证获得最低的缺页率。但是由于无法预知哪一个页面是未来最长时间内不再被访问的，因而该算法是无法实现的；
- **先进先出（FIFO）算法**： 淘汰最先进入内存的页面，即选择在内存中驻留最久的页面予以淘汰。
- **最近最久未使用（LRU）算法**： 根据页面调入内存后的使用情况进行决策，选择最近最久未使用的页面予以淘汰； 该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，当需要淘汰一个页面的适合，选择现有页面中T值最大的。
- **最近未使用算法（NUR）**： 每页设置一个访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列；当某个页面被访问时，其访问位置1。淘汰时，检查其访问位，如果是0，就换出；若为1，则重新将它置0；再按FIFO算法检查下一个页面，到队列中的最后一个页面时，若其访问位仍为1，则再返回到队首再去检查第一个页面。

## 查看占用端口和进程ID

通过进程ID查看占用的端口：

`ps -ef |grep 进程ID`

通过端口号查看占用的进程ID：

`netstat -nap | grep 端口号`

## 虚拟地址/物理地址

- **实模式**

![image-20211213205829290](https://cdn.jsdelivr.net/gh/TaoCesc/blogImages/imgs/image-20211213205829290.png)

A程序和B程序从磁盘直接加载进内存中运行，得到的地址都是物理地址，**我们都知道内存是连续的，现在假设A程序是恶意程序，他现在可以通过自己运行时所获取的物理地址加上偏移就可以进入B程序中，可以篡改B程序的指令或者数据，导致B程序崩溃或者出错**

- **保护模式**

![image-20211213205929205](https://cdn.jsdelivr.net/gh/TaoCesc/blogImages/imgs/image-20211213205929205.png)

**在程序从磁盘加载进内存的中间加了一个中间层，即就是虚拟地址，在程序编译，链接的时候先映射进虚拟地址，在运行的时候会在映射进物理地址**

## Java的管道实现

- 向管道写数据

```java
public void test1() throws IOException{
    String str = "test";
    //创建管道
    Pipe pipe = Pipe.open();
    //向管道写输入
    Pipe.SinkChannel sinChannel = pipe.sink();
    //通过SinkChannel的write（）方法写数据
    ByBuffer buf = ByteBuffer.allocate(1024);
    buf.clear();
    buf.put(str.getBytes());
    while(buf.hasRemaining()){
        sinkChannel.write(buf);
    }
}
```

- 向管道读数据

```java
public void test2() throws IOException{
    //创建管道
    Pipe pipe = Pipe.open();
    //从管道读取数据
    Pipe.SourceChannel sourceChannel = pipe.source();
    
    ByteBuffer buf = ByteBuffer.allocate(1024);
    sourceChannel.
}
```

## IO多路复用

IO多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；一旦某个 文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄时会阻塞应用程序，交出cpu。多路是指**网络连接**，复用指的是**同一个线程**。

> 没有IO多路复用机制时，有BIO、NIO两种实现方式，但是有一定的问题

### 同步阻塞（BIO）

- 服务器采用单线程，当accept一个请求后，在recv或send调用阻塞时，将无法accept其他请求，**无法处理并发**

### 同步非阻塞（NIO）

- 服务器accept一个请求后，加入fds集合，每次轮询一遍fds集合（非阻塞）数据，没有数据则立即返回错误，**每次轮询所有fd（包括没有发生读写事件的fd）**会很浪费cpu

### IO多路复用

- 服务器采用单线程通过`select\epoll` 等系统调用获取fd列表，遍历有事件的fd进行accept/recv/send，使其能`支持更多的并发连接请求`

